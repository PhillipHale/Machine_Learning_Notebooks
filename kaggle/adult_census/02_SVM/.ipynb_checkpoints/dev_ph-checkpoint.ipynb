{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "![](./media/intro-to-machine-learning-by-microsoft-ventures-27-638.jpg)\n",
    "\n",
    "_[Source](https://www.slideshare.net/microsoftventures/microsoft-ventures-workshop)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Create Dummy Variables\n",
    "\n",
    "Label encoding using [get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) function to reach dummy variables 0 and 1 for the different categories. Then remove the previously used original categorical columns, and going forward we use the created dummy columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educationNum</th>\n",
       "      <th>hoursPerWeek</th>\n",
       "      <th>income</th>\n",
       "      <th>netCapital</th>\n",
       "      <th>isWhite</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isHusband</th>\n",
       "      <th>USA</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>jobtype_government</th>\n",
       "      <th>jobtype_other</th>\n",
       "      <th>jobtype_private</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>77053</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>-4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>132870</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>186061</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>-4356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>140359</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>-3900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>264663</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>-3900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educationNum  hoursPerWeek  income  netCapital  isWhite  \\\n",
       "0   90   77053             9            40       0       -4356      1.0   \n",
       "1   82  132870             9            18       0       -4356      1.0   \n",
       "2   66  186061            10            40       0       -4356      0.0   \n",
       "3   54  140359             4            40       0       -3900      1.0   \n",
       "4   41  264663            10            40       0       -3900      1.0   \n",
       "\n",
       "   isMarried  isHusband  USA  sex_Male  jobtype_government  jobtype_other  \\\n",
       "0        0.0        0.0  1.0         0                   0              1   \n",
       "1        0.0        0.0  1.0         0                   0              0   \n",
       "2        0.0        0.0  1.0         0                   0              1   \n",
       "3        0.0        0.0  1.0         0                   0              0   \n",
       "4        0.0        0.0  1.0         0                   0              0   \n",
       "\n",
       "   jobtype_private  \n",
       "0                0  \n",
       "1                1  \n",
       "2                0  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Code comparison\n",
    "import time\n",
    "\n",
    "# import dataset\n",
    "df = pd.read_csv(\"../cleanedAdultCensus.csv\")\n",
    "\n",
    "#  consolidate capital gain/loss into a single net metric.\n",
    "df['netCapital'] = df['capitalGain']  - df['capitalLoss']\n",
    "\n",
    "# create new variable categorizes worked hours per week\n",
    "df.loc[df.hoursPerWeek > 40, \"workhrs_\"] = \"overtime\"\n",
    "df.loc[(df.hoursPerWeek <= 40) & (df.hoursPerWeek >= 30), \"workhrs_\"] = \"fulltime\"\n",
    "df.loc[(df.hoursPerWeek < 30 ) & (df.hoursPerWeek >= 20), \"workhrs_\"] = \"partime\"\n",
    "df.loc[df.hoursPerWeek < 20, \"workhrs_\"] = \"limited\"\n",
    "\n",
    "#maritalStatus_old = {'Widowed': 'separate', 'Divorced': 'separate', 'Separated': 'separate', 'Never-married': 'single', 'Married-civ-spouse': 'married', 'Married-spouse-absent': 'a_other', 'Married-AF-spouse': 'a_other'}\n",
    "#maritalStatus_ = {'Widowed': 'single', 'Divorced': 'single', 'Separated': 'single', 'Never-married': 'single', 'Married-civ-spouse': 'married', 'Married-spouse-absent': 'a_other', 'Married-AF-spouse': 'a_other'}\n",
    "#df['maritalStatus_'] = df.maritalStatus.map(lambda x: maritalStatus_[x])\n",
    "\n",
    "# compute the nearest 10 for person's decade birth\n",
    "#df['age_decade'] = (df.age // 10) * 10\n",
    "\n",
    "# one-hot encode `income` and race and maritalStatus, relationship, nativeCountry\n",
    "df.loc[df.income == \"<=50K\", 'income'] = 0 \n",
    "df.loc[df.income == \">50K\", 'income'] = 1\n",
    "\n",
    "df.loc[df.race == \"White\", 'isWhite'] = 1\n",
    "df.loc[df.race != \"White\", 'isWhite'] = 0\n",
    "\n",
    "df.loc[df.maritalStatus == 'Married-AF-spouse', 'isMarried'] = 1\n",
    "df.loc[df.maritalStatus != 'Married-AF-spouse', 'isMarried'] = 0\n",
    "\n",
    "df.loc[df.relationship == 'Husband', 'isHusband'] = 1\n",
    "df.loc[df.relationship != 'Husband', 'isHusband'] = 0\n",
    "\n",
    "df.loc[df.nativeCountry == 'United-States', 'USA'] = 1\n",
    "df.loc[df.nativeCountry != 'United-States', 'USA'] = 0\n",
    "\n",
    "\n",
    "# drop unneeded columns\n",
    "#'educationNum','hoursPerWeek',\n",
    "unneeded_columns = ['workclass', 'education', 'maritalStatus','race',\n",
    "                    'occupation', 'capitalGain', 'capitalLoss', 'nativeCountry', 'relationship',\n",
    "                   'education_','workhrs_']\n",
    "df.drop(unneeded_columns, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "categorical_variables =  ['sex', 'jobtype' ]\n",
    "for var in categorical_variables:\n",
    "    category_list = 'var'+'_'+var\n",
    "    category_list = pd.get_dummies(df[var], prefix=var, drop_first=True)\n",
    "    _temp = df.join(category_list)\n",
    "    df = _temp\n",
    "    \n",
    "    \n",
    "df.drop(categorical_variables, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Correlation\n",
    "Utilize Perason correlation coefficient to gain a better understanding of the predictor varaibales and their strength in relationship to whether income is greater or less than 50K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0.234037\n",
       "educationNum          0.335154\n",
       "hoursPerWeek          0.229689\n",
       "income                1.000000\n",
       "netCapital            0.214428\n",
       "isWhite               0.085224\n",
       "isHusband             0.401035\n",
       "sex_Male              0.215980\n",
       "jobtype_government    0.061903\n",
       "jobtype_other         0.079348\n",
       "jobtype_private       0.078528\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = df.corr()\n",
    "#df_corr['income'].sort_values(ascending=False)\n",
    "correlation_target = abs(df_corr.income)\n",
    "corr_matrix = correlation_target[correlation_target>0.05]\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Inflation Factor for Heatmap Predictors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.6</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>fnlwgt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.1</td>\n",
       "      <td>educationNum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.4</td>\n",
       "      <td>hoursPerWeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8</td>\n",
       "      <td>income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1</td>\n",
       "      <td>netCapital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>isWhite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>isMarried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.1</td>\n",
       "      <td>isHusband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.4</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.6</td>\n",
       "      <td>sex_Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.1</td>\n",
       "      <td>jobtype_government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.4</td>\n",
       "      <td>jobtype_other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.9</td>\n",
       "      <td>jobtype_private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor            features\n",
       "0          8.6                 age\n",
       "1          4.0              fnlwgt\n",
       "2         15.1        educationNum\n",
       "3         11.4        hoursPerWeek\n",
       "4          1.8              income\n",
       "5          1.1          netCapital\n",
       "6          7.0             isWhite\n",
       "7          1.0           isMarried\n",
       "8          3.1           isHusband\n",
       "9          9.4                 USA\n",
       "10         4.6            sex_Male\n",
       "11         2.1  jobtype_government\n",
       "12         1.4       jobtype_other\n",
       "13         5.9     jobtype_private"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://etav.github.io/python/vif_factor_python.html\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# For each X, calculate VIF and save in dataframe\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "vif[\"features\"] = df.columns\n",
    "print(\"Variance Inflation Factor for Heatmap Predictors\")\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.585185</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.968185</td>\n",
       "      <td>fnlwgt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.102226</td>\n",
       "      <td>educationNum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.430298</td>\n",
       "      <td>hoursPerWeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.784836</td>\n",
       "      <td>income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.075494</td>\n",
       "      <td>netCapital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.951529</td>\n",
       "      <td>isWhite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.001627</td>\n",
       "      <td>isMarried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.118372</td>\n",
       "      <td>isHusband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.361052</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.600417</td>\n",
       "      <td>sex_Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.060186</td>\n",
       "      <td>jobtype_government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.418556</td>\n",
       "      <td>jobtype_other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.912702</td>\n",
       "      <td>jobtype_private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor            features\n",
       "0     8.585185                 age\n",
       "1     3.968185              fnlwgt\n",
       "2    15.102226        educationNum\n",
       "3    11.430298        hoursPerWeek\n",
       "4     1.784836              income\n",
       "5     1.075494          netCapital\n",
       "6     6.951529             isWhite\n",
       "7     1.001627           isMarried\n",
       "8     3.118372           isHusband\n",
       "9     9.361052                 USA\n",
       "10    4.600417            sex_Male\n",
       "11    2.060186  jobtype_government\n",
       "12    1.418556       jobtype_other\n",
       "13    5.912702     jobtype_private"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analysis__ after several iterations of performing the Variance Inflation Factor calcuation and review the results, above is the final output. The core variables removed all together or re-categoriezed were `race, maritalStatus, relationship, nativeCountry` as many of the variables had high variance inflation values. Therefore, some of these variables had to be removed or re-categoried in to new features as the variables would pose high risk of multicolinarity in explaining the features in the dataset in solving this classificaiton problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create explanaotry and response variables for classification training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all posible variables\n",
      "['age', 'fnlwgt', 'educationNum', 'hoursPerWeek', 'netCapital', 'isWhite', 'isMarried', 'isHusband', 'USA', 'sex_Male', 'jobtype_government', 'jobtype_other', 'jobtype_private']\n",
      "\n",
      "Summary Statistics for the Response Variable: `INCOME`\n",
      "Average Income (Mean):  0.241\n",
      "Standard Deviation Income:  0.428\n",
      "Mim Income:  0.000\n",
      "Max Income:  1.000\n"
     ]
    }
   ],
   "source": [
    "# list of all possible variables\n",
    "variables_ = df.columns.values.tolist()\n",
    "#variables_ = corr_matrix.index.tolist()\n",
    "variables_.remove(\"income\")\n",
    "print(\"List of all posible variables\")\n",
    "print(variables_)\n",
    "\n",
    "# define variables for classificaiton training\n",
    "y=df['income']\n",
    "X=df[variables_]\n",
    "\n",
    "print(\"\")\n",
    "print(\"Summary Statistics for the Response Variable: `INCOME`\")\n",
    "print(\"Average Income (Mean):  {:.3f}\".format(y.mean()))\n",
    "print(\"Standard Deviation Income:  {:.3f}\".format(y.std()))\n",
    "print(\"Mim Income:  {:.3f}\".format(y.min()))\n",
    "print(\"Max Income:  {:.3f}\".format(y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is imbalanced, use `roc_auc` metric to accout for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Traning accuracy: 0.837\n",
      "Logit test accuracy: 0.836\n",
      "Model Training Time=0.4510025978088379s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "start = time.time()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Logit Traning accuracy: {:.3f}'.format(accuracy_score(y_train, logreg.predict(X_train))))\n",
    "print('Logit test accuracy: {:.3f}'.format(accuracy_score(y_test, logreg.predict(X_test))))\n",
    "end = time.time()\n",
    "print(\"Model Training Time=\"+str(end-start)+\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Support Vector Machine\n",
    "\n",
    "Next we seek to train a model using the __Support Vector Machine (SVM)__ to compare ho well these supervised learning methods can best solve this classificaiton problem. We will be utilzing various SVM kernel functions such as `SVC` and `LinearSVC` kernerls to assist in the model training computation in finding the appropriate hyperplane for the classification to make a decision as to whether a given individual's income is greater or less than 50K. \n",
    "\n",
    "Use cost of error imporved with the parameter `class_weight` to adjust the weights more heavier on those that do not earn income >50K which is automatically adjusted. \n",
    "\n",
    "__General References__\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "* http://cs229.stanford.edu/notes/cs229-notes3.pdf\n",
    "\n",
    "\n",
    "First we train SVM using the __Support Vector Classifier (SVC)__ kernel with classification valuation `C` = 1 which is the default parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Time=106.80650854110718s\n",
      "SVM Traning accuracy: 0.841\n",
      "SVM test accuracy: 0.809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "start = time.time()\n",
    "svc = SVC(class_weight='balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Model Training Time=\"+str(end-start)+\"s\")\n",
    "\n",
    "print('SVM Traning accuracy: {:.3f}'.format(accuracy_score(y_train, svc.predict(X_train))))\n",
    "print('SVM test accuracy: {:.3f}'.format(accuracy_score(y_test, svc.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the results are show where the Training dataset accuracy is 84.1% and the test dataset accuracy is 80.9%. We can see that the default SVC kernel aided in not overfitting this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Time=18.129910707473755s\n",
      "SVM - Scaler Training accuracy:  0.827\n",
      "SVM - Scaler Testing accuracy:  0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "start = time.time()\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "end = time.time()\n",
    "print(\"Model Training Time=\"+str(end-start)+\"s\")\n",
    "\n",
    "print(\"SVM - Scaler Training accuracy:  {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"SVM - Scaler Testing accuracy:  {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM - Scaler Training accuracy:  0.808\n",
    "SVM - Scaler Testing accuracy:  0.806"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch \n",
    "\n",
    "We are looking to test \n",
    "\n",
    "That means we have created 80 different models. \n",
    "With a 5 fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*4*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required =1673.6280579566956s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start = time.time()\n",
    "clf = SVC()\n",
    "param_grid = [{'kernel':['rbf'],'gamma':[50,5,10,0.5],\n",
    "             'C':[10,0.1,0.001] }]\n",
    "gsv = GridSearchCV(clf,param_grid,cv=5,n_jobs=-1)\n",
    "gsv.fit(X_train_scaled, y_train)\n",
    "end = time.time()\n",
    "print(\"Time required =\"+str(end-start)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HyperParameter:  {'C': 10, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best Accuracy: 83.85%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Best HyperParameter:  {'C': 10, 'gamma': 0.5, 'kernel': 'rbf'}\n",
    "Best Accuracy: 82.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.836\n",
      "Model Training Time=18.30422019958496s\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy for best GriSearchCV SVM + Hyperparameters\n",
    "start = time.time()\n",
    "gsv_classifier = SVC(C = 10,kernel='rbf', gamma=0.5)\n",
    "gsv_classifier = gsv_classifier.fit(X_train_scaled, y_train)\n",
    "gsv_classifier_test_accuracy = gsv_classifier.score(X_test_scaled, y_test)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Test Accuracy:  {:.3f}\".format(gsv_classifier_test_accuracy))\n",
    "print(\"Model Training Time=\"+str(end-start)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.832\n",
      "Model Training Time=12.51808762550354s\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy for best GriSearchCV SVM + Hyperparameters\n",
    "start = time.time()\n",
    "gsv_classifier = SVC(C = 10,kernel='linear')\n",
    "gsv_classifier = gsv_classifier.fit(X_train_scaled, y_train)\n",
    "gsv_classifier_test_accuracy = gsv_classifier.score(X_test_scaled, y_test)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Test Accuracy:  {:.3f}\".format(gsv_classifier_test_accuracy))\n",
    "print(\"Model Training Time=\"+str(end-start)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with Linear Kernel\n",
    "\n",
    "_https://github.com/benhhu/HDSMeetup/blob/6dec21eb2a2fdc9a85e0c856618f280f83c147aa/11072016SVM_classification.ipynb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([   1,   10,  100, 1000], dtype=int32)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 10**np.arange(0,4)\n",
    "param_grid = dict(C=C)\n",
    "model = SVC(random_state=0, probability=True, kernel=\"linear\")\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656017405279218\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.C)\n",
    "svmlTunedC = grid.best_estimator_.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./models/linear_gsv_grid_020920.pkl\" , 'wb') as file: pickle.dump(grid.best_estimator_, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647667096827268"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, grid.predict_proba(X_test_scaled)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647667096827268"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, grid.predict_proba(X_test_scaled)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      4966\n",
      "           1       0.73      0.47      0.57      1547\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6513\n",
      "   macro avg       0.79      0.71      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Form a prediction set\n",
    "predictions = grid.predict(X_test_scaled)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.833\n",
      "Model Training Time=65.35101842880249s\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy for best GriSearchCV SVM + Hyperparameters\n",
    "start = time.time()\n",
    "gsv_classifier = SVC(C = 1,kernel='linear', random_state=0, probability=True)\n",
    "gsv_classifier = gsv_classifier.fit(X_train_scaled, y_train)\n",
    "gsv_classifier_test_accuracy = gsv_classifier.score(X_test_scaled, y_test)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Test Accuracy:  {:.3f}\".format(gsv_classifier_test_accuracy))\n",
    "print(\"Model Training Time=\"+str(end-start)+\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      4966\n",
      "           1       0.73      0.47      0.57      1547\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6513\n",
      "   macro avg       0.79      0.71      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Form a prediction set\n",
    "predictions = gsv_classifier.predict(X_test_scaled)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.31770005,  0.6374068 ,  4.34213976,  1.892803  , 14.72982607,\n",
       "        0.08047854,  1.        ,  1.18896121,  0.15840081, -0.05367301,\n",
       "        0.07818298, -0.34946836,  0.12386427])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv_classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'fnlwgt',\n",
       " 'educationNum',\n",
       " 'hoursPerWeek',\n",
       " 'netCapital',\n",
       " 'isWhite',\n",
       " 'isMarried',\n",
       " 'isHusband',\n",
       " 'USA',\n",
       " 'sex_Male',\n",
       " 'jobtype_government',\n",
       " 'jobtype_other',\n",
       " 'jobtype_private']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def feature_importances(coef, names):\n",
    "    #https://stackoverflow.com/a/41601281\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_names = X_train.columns.to_list()\n",
    "feature_importances(abs(gsv_classifier.coef_[0]), features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm with the best parameters and CV:  83.30388063838005\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/mehrdaddarraji/us-hr-bill-classifier/blob/4bf9044988c385f02c4cf8ebe390fdc31c671782/train_predict.ipynb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pred_svm = cross_val_score(gsv_classifier, X_train_scaled, y_train, cv=5)\n",
    "# prints the accuracy of your neural net\n",
    "print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[18703  1051]\n",
      " [ 3294  3000]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    " # CONFUSION MATRIX EVALUATION\n",
    "# running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "pred_svm = cross_val_predict(gsv_classifier, X_train_scaled, y_train, cv=10)\n",
    "\n",
    "conf_mat = confusion_matrix(y_train, pred_svm)\n",
    "print(\"Confusion matrix: \\n\", conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18703,  1051],\n",
       "       [ 3294,  3000]], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     19754\n",
      "           1       0.74      0.48      0.58      6294\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     26048\n",
      "   macro avg       0.80      0.71      0.74     26048\n",
      "weighted avg       0.82      0.83      0.82     26048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Form a prediction set\n",
    "predictions = gsv_classifier.predict(X_train_scaled)\n",
    "print(classification_report(y_train,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX EVALUATION\n",
    "# running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "print(\"Confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM\n",
    "\n",
    "We are choosing to use the _Ridge regression_ with the __L1 Normalization__ to set the weights in the LinearSVM kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearSVC(loss='l2', penalty='l1', dual=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\phhale\\AppData\\Local\\Continuum\\anaconda3\\envs\\bril\\lib\\site-packages\\sklearn\\pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8267248994605458"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), SVC(decision_function_shape='ovo'))\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://nbviewer.jupyter.org/github/jakemdrew/EducationDataNC/blob/master/2018/Models/.ipynb_checkpoints/2018AvgACTScores-checkpoint.ipynb\n",
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://nbviewer.jupyter.org/github/jakemdrew/EducationDataNC/blob/master/2018/Models/.ipynb_checkpoints/2018AvgACTScores-checkpoint.ipynb\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make new estimator compatible for use with GridSearchCV() and cross_validate()\n",
    "# -  Cap predict function for LinearRegression between 0 and 100\n",
    "# -  See: Roll your own estimator links above for details. \n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class CappedLinearRegression(LinearRegression):\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.clip(super(CappedLinearRegression, self).predict(X), 0, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=CappedLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "            normalize=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'normalize': (True, False), 'fit_intercept': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "linreg = CappedLinearRegression()\n",
    "parameters = {'normalize':(True,False), 'fit_intercept':(True,False)}\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CappedLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "            normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the parameterization of the best estimator\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 0.25698\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 51.439\n",
      "The average RMSE for all cv folds is: \t\t\t 0.34501\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256406</td>\n",
       "      <td>51.782408</td>\n",
       "      <td>0.346596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.265504</td>\n",
       "      <td>51.921621</td>\n",
       "      <td>0.353688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250419</td>\n",
       "      <td>50.820762</td>\n",
       "      <td>0.337775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>52.221215</td>\n",
       "      <td>0.344309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.261450</td>\n",
       "      <td>51.158665</td>\n",
       "      <td>0.348505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.248673</td>\n",
       "      <td>50.899687</td>\n",
       "      <td>0.337664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.253525</td>\n",
       "      <td>51.324425</td>\n",
       "      <td>0.341316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.265075</td>\n",
       "      <td>51.429387</td>\n",
       "      <td>0.352592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.253363</td>\n",
       "      <td>51.585682</td>\n",
       "      <td>0.341340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.258184</td>\n",
       "      <td>51.243562</td>\n",
       "      <td>0.346344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE       MAPE      RMSE\n",
       "0  0.256406  51.782408  0.346596\n",
       "1  0.265504  51.921621  0.353688\n",
       "2  0.250419  50.820762  0.337775\n",
       "3  0.257178  52.221215  0.344309\n",
       "4  0.261450  51.158665  0.348505\n",
       "5  0.248673  50.899687  0.337664\n",
       "6  0.253525  51.324425  0.341316\n",
       "7  0.265075  51.429387  0.352592\n",
       "8  0.253363  51.585682  0.341340\n",
       "9  0.258184  51.243562  0.346344"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 0.29103\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 89.096\n",
      "The average RMSE for all cv folds is: \t\t\t 0.44569\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.290245</td>\n",
       "      <td>89.092745</td>\n",
       "      <td>0.444867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.308941</td>\n",
       "      <td>89.141177</td>\n",
       "      <td>0.465440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.284809</td>\n",
       "      <td>89.033530</td>\n",
       "      <td>0.438616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288992</td>\n",
       "      <td>89.131751</td>\n",
       "      <td>0.443664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303069</td>\n",
       "      <td>89.094155</td>\n",
       "      <td>0.458973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.284907</td>\n",
       "      <td>89.060114</td>\n",
       "      <td>0.438952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.284831</td>\n",
       "      <td>89.071211</td>\n",
       "      <td>0.438769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.292157</td>\n",
       "      <td>89.092968</td>\n",
       "      <td>0.447021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.279830</td>\n",
       "      <td>89.084591</td>\n",
       "      <td>0.433056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.292492</td>\n",
       "      <td>89.158394</td>\n",
       "      <td>0.447587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE       MAPE      RMSE\n",
       "0  0.290245  89.092745  0.444867\n",
       "1  0.308941  89.141177  0.465440\n",
       "2  0.284809  89.033530  0.438616\n",
       "3  0.288992  89.131751  0.443664\n",
       "4  0.303069  89.094155  0.458973\n",
       "5  0.284907  89.060114  0.438952\n",
       "6  0.284831  89.071211  0.438769\n",
       "7  0.292157  89.092968  0.447021\n",
       "8  0.279830  89.084591  0.433056\n",
       "9  0.292492  89.158394  0.447587"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = SVR(C=0.001, cache_size=1999, coef0=0.0, degree=3, epsilon=0.1,gamma='auto',\n",
    "                   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bril",
   "language": "python",
   "name": "bril"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
